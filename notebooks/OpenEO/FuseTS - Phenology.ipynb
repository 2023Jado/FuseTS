{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b7921ab",
   "metadata": {},
   "source": [
    "# FuseTS - Phenology example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956274d1",
   "metadata": {},
   "source": [
    "## Setting up the OpenEO process\n",
    "The first step includes setting up the OpenEO processing through the [OpenEO Python Client](https://open-eo.github.io/openeo-python-client/). Since the Whittaker algorithm is integrated as an [user defined process](https://open-eo.github.io/openeo-python-client/cookbook/udp_sharing.html), we can use the `datacube_from_process` function to execute the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84c6b75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openeo\n",
    "import json\n",
    "import pandas as pd\n",
    "import xarray\n",
    "import matplotlib.pyplot as plt\n",
    "from openeo.rest.conversions import timeseries_json_to_pandas\n",
    "from openeo.metadata import CollectionMetadata\n",
    "from shapely.geometry import box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8566da74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated using refresh token.\n"
     ]
    }
   ],
   "source": [
    "connection = openeo.connect(\"openeo.vito.be\").authenticate_oidc()\n",
    "service = 'phenology'\n",
    "namespace = 'u:bramjanssen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edd56ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <script>\n",
       "    if (!window.customElements || !window.customElements.get('openeo-process')) {\n",
       "        var el = document.createElement('script');\n",
       "        el.src = \"https://cdn.jsdelivr.net/npm/@openeo/vue-components@2/assets/openeo.min.js\";\n",
       "        document.head.appendChild(el);\n",
       "\n",
       "        var font = document.createElement('font');\n",
       "        font.as = \"font\";\n",
       "        font.type = \"font/woff2\";\n",
       "        font.crossOrigin = true;\n",
       "        font.href = \"https://use.fontawesome.com/releases/v5.13.0/webfonts/fa-solid-900.woff2\"\n",
       "        document.head.appendChild(font);\n",
       "    }\n",
       "    </script>\n",
       "    <openeo-process>\n",
       "        <script type=\"application/json\">{\"show-graph\": true, \"provide-download\": false, \"process\": {\"description\": \"# Phenology\\n\\n## Description\\n\\n\\n\", \"id\": \"phenology\", \"parameters\": [{\"description\": \"A data cube.\", \"name\": \"data\", \"schema\": {\"subtype\": \"raster-cube\", \"type\": \"object\"}}], \"summary\": \"\"}}</script>\n",
       "    </openeo-process>\n",
       "    "
      ],
      "text/plain": [
       "{'description': '# Phenology\\n\\n## Description\\n\\n\\n',\n",
       " 'id': 'phenology',\n",
       " 'parameters': [{'description': 'A data cube.',\n",
       "   'name': 'data',\n",
       "   'schema': {'subtype': 'raster-cube', 'type': 'object'}}],\n",
       " 'summary': ''}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connection.describe_process(service, namespace=namespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "020ef2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spat_ext = {\n",
    "          \"type\": \"Polygon\",\n",
    "          \"coordinates\": [\n",
    "            [\n",
    "              [\n",
    "                5.170012098271149,\n",
    "                51.25062964728295\n",
    "              ],\n",
    "              [\n",
    "                5.17085904378298,\n",
    "                51.24882567194015\n",
    "              ],\n",
    "              [\n",
    "                5.17857421368097,\n",
    "                51.2468515482926\n",
    "              ],\n",
    "              [\n",
    "                5.178972704726344,\n",
    "                51.24982704376254\n",
    "              ],\n",
    "              [\n",
    "                5.170012098271149,\n",
    "                51.25062964728295\n",
    "              ]\n",
    "            ]\n",
    "          ]\n",
    "        }\n",
    "temp_ext = [\"2022-01-01\",\"2022-12-31\"]\n",
    "smoothing_lambda = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b664aaa6",
   "metadata": {},
   "source": [
    "To begin, we calculate the base NDVI data cube. In the subsequent steps, we utilize this data cube to implement Whittaker smoothing. Finally, we compute time series for both the base NDVI and the smoothed version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8f472d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = connection.load_collection('SENTINEL2_L2A_SENTINELHUB',\n",
    "                                spatial_extent=spat_ext,\n",
    "                                temporal_extent=temp_ext,\n",
    "                                bands=[\"B04\",\"B08\",\"SCL\"])\n",
    "base_cloudmasked = base.process(\"mask_scl_dilation\", data=base, scl_band_name=\"SCL\")\n",
    "base_ndvi = base_cloudmasked.ndvi(red=\"B04\", nir=\"B08\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41a94c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bramjanssen/.local/lib/python3.6/site-packages/openeo/metadata.py:255: UserWarning: No cube:dimensions metadata\n",
      "  complain(\"No cube:dimensions metadata\")\n"
     ]
    }
   ],
   "source": [
    "phenology = connection.datacube_from_process(service, namespace=f'https://openeo.vito.be/openeo/1.1/processes/{namespace}/{service}', data=base_ndvi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7dc2ffda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00 Job 'j-69124a1f99934e9f9888989daad62010': send 'start'\n",
      "0:00:22 Job 'j-69124a1f99934e9f9888989daad62010': queued (progress N/A)\n",
      "0:00:27 Job 'j-69124a1f99934e9f9888989daad62010': queued (progress N/A)\n",
      "0:00:33 Job 'j-69124a1f99934e9f9888989daad62010': queued (progress N/A)\n",
      "0:00:41 Job 'j-69124a1f99934e9f9888989daad62010': queued (progress N/A)\n",
      "0:00:51 Job 'j-69124a1f99934e9f9888989daad62010': running (progress N/A)\n",
      "0:01:04 Job 'j-69124a1f99934e9f9888989daad62010': running (progress N/A)\n",
      "0:01:23 Job 'j-69124a1f99934e9f9888989daad62010': running (progress N/A)\n",
      "0:01:42 Job 'j-69124a1f99934e9f9888989daad62010': running (progress N/A)\n",
      "0:02:06 Job 'j-69124a1f99934e9f9888989daad62010': running (progress N/A)\n",
      "0:02:36 Job 'j-69124a1f99934e9f9888989daad62010': running (progress N/A)\n",
      "0:03:14 Job 'j-69124a1f99934e9f9888989daad62010': error (progress N/A)\n",
      "Your batch job 'j-69124a1f99934e9f9888989daad62010' failed. Error logs:\n",
      "[{'id': '[1685633154434, 132778]', 'time': '2023-06-01T15:25:54.434Z', 'level': 'error', 'message': 'Task 117 in stage 12.0 failed 4 times; aborting job'}, {'id': '[1685633154442, 133115]', 'time': '2023-06-01T15:25:54.442Z', 'level': 'error', 'message': 'Stage error: Job aborted due to stage failure: Task 117 in stage 12.0 failed 4 times, most recent failure: Lost task 117.3 in stage 12.0 (TID 396) (epod184.vgt.vito.be executor 92): java.lang.AssertionError: assertion failed: Row/col intervals must begin before they end\\n\\tat scala.Predef$.assert(Predef.scala:223)\\n\\tat geotrellis.spark.regrid.Regrid$Interval.<init>(Regrid.scala:34)\\n\\tat geotrellis.spark.regrid.Regrid$Interval.intersect(Regrid.scala:38)\\n\\tat geotrellis.spark.regrid.Regrid$.$anonfun$apply$6(Regrid.scala:119)\\n\\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\\n\\tat scala.collection.Iterator.foreach(Iterator.scala:943)\\n\\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\\n\\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\\n\\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\\n\\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\\n\\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\\n\\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\\n\\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\\n\\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\\n\\tat geotrellis.spark.regrid.Regrid$.$anonfun$apply$4(Regrid.scala:111)\\n\\tat scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)\\n\\tat scala.collection.Iterator.foreach(Iterator.scala:943)\\n\\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\\n\\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\\n\\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\\n\\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\\n\\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\\n\\tat scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)\\n\\tat scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)\\n\\tat scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)\\n\\tat geotrellis.spark.regrid.Regrid$.$anonfun$apply$2(Regrid.scala:106)\\n\\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\\n\\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\\n\\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:101)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n\\nDriver stacktrace:'}, {'id': '[1685633154709, 28667]', 'time': '2023-06-01T15:25:54.709Z', 'level': 'error', 'message': 'OpenEO batch job failed: Exception during Spark execution: assertion failed: Row/col intervals must begin before they end'}, {'id': '[1685633154956, 0]', 'time': '2023-06-01T15:25:54.956Z', 'level': 'error', 'message': 'Still have 1 requests outstanding when connection from epod191.vgt.vito.be/192.168.207.103:34757 is closed'}, {'id': '[1685633154956, 424]', 'time': '2023-06-01T15:25:54.956Z', 'level': 'error', 'message': 'Executor self-exiting due to : Driver epod191.vgt.vito.be:34757 disassociated! Shutting down.'}, {'id': '[1685633154991, 0]', 'time': '2023-06-01T15:25:54.991Z', 'level': 'error', 'message': 'Failed to send RPC RPC 8592195285451821559 to epod191.vgt.vito.be/192.168.207.103:34757: java.io.IOException: Broken pipe'}, {'id': '[1685633155140, 9583]', 'time': '2023-06-01T15:25:55.140Z', 'level': 'error', 'message': 'Executor self-exiting due to : Cannot register with driver: spark://CoarseGrainedScheduler@epod191.vgt.vito.be:34757'}, {'id': '[1685633181903, 1795917]', 'time': '2023-06-01T15:26:21.903Z', 'level': 'error', 'message': 'YARN application status reports error diagnostics: User application exited with status 1'}]\n",
      "Full logs can be inspected in an openEO (web) editor or with `connection.job('j-69124a1f99934e9f9888989daad62010').logs()`.\n"
     ]
    },
    {
     "ename": "JobFailedException",
     "evalue": "Batch job 'j-69124a1f99934e9f9888989daad62010' didn't finish successfully. Status: error (after 0:03:14).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJobFailedException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-482481f43151>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     'udf-dependency-archives': [\n\u001b[1;32m      3\u001b[0m          \u001b[0;34m'https://artifactory.vgt.vito.be:443/auxdata-public/ai4food/fusets_venv.zip#tmp/venv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;34m'https://artifactory.vgt.vito.be:443/auxdata-public/ai4food/fusets.zip#tmp/venv_static'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     ]\n\u001b[1;32m      6\u001b[0m })\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/openeo/rest/datacube.py\u001b[0m in \u001b[0;36mexecute_batch\u001b[0;34m(self, outputfile, out_format, print, max_poll_interval, connection_retry_interval, job_options, **format_options)\u001b[0m\n\u001b[1;32m   1990\u001b[0m         return job.run_synchronous(\n\u001b[1;32m   1991\u001b[0m             \u001b[0moutputfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1992\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_poll_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_poll_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection_retry_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconnection_retry_interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1993\u001b[0m         )\n\u001b[1;32m   1994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/openeo/rest/job.py\u001b[0m in \u001b[0;36mrun_synchronous\u001b[0;34m(self, outputfile, print, max_poll_interval, connection_retry_interval)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;34m\"\"\"Start the job, wait for it to finish and download result\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         self.start_and_wait(\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_poll_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_poll_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection_retry_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconnection_retry_interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         )\n\u001b[1;32m    207\u001b[0m         \u001b[0;31m# TODO #135 support multi file result sets too?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/openeo/rest/job.py\u001b[0m in \u001b[0;36mstart_and_wait\u001b[0;34m(self, print, max_poll_interval, connection_retry_interval, soft_error_max)\u001b[0m\n\u001b[1;32m    286\u001b[0m             raise JobFailedException(\n\u001b[1;32m    287\u001b[0m                 \u001b[0;34mf\"Batch job {self.job_id!r} didn't finish successfully. Status: {status} (after {elapsed()}).\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m                 \u001b[0mjob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m             )\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJobFailedException\u001b[0m: Batch job 'j-69124a1f99934e9f9888989daad62010' didn't finish successfully. Status: error (after 0:03:14)."
     ]
    }
   ],
   "source": [
    "phenology_job = phenology.execute_batch(out_format=\"netcdf\", title=f'FuseTS - Phenology', job_options={\n",
    "    'udf-dependency-archives': [\n",
    "         'https://artifactory.vgt.vito.be:443/auxdata-public/ai4food/fusets_venv.zip#tmp/venv',\n",
    "        'https://artifactory.vgt.vito.be:443/auxdata-public/ai4food/fusets.zip#tmp/venv_static'\n",
    "    ]\n",
    "})\n",
    "phenology_job.get_results().download_file('./phenology.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad5f438",
   "metadata": {},
   "source": [
    "## Visualising the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0241bf5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ImplementsDatasetReduce._reduce_method.<locals>.wrapped_func of <xarray.Dataset>\n",
       "Dimensions:  (t: 1, x: 65, y: 45)\n",
       "Coordinates:\n",
       "  * t        (t) datetime64[ns] 2020-01-01\n",
       "  * x        (x) float64 6.514e+05 6.514e+05 6.515e+05 ... 6.521e+05 6.521e+05\n",
       "  * y        (y) float64 5.68e+06 5.68e+06 5.68e+06 ... 5.68e+06 5.68e+06\n",
       "Data variables:\n",
       "    crs      |S1 b''\n",
       "    var      (t, y, x) float64 0.8873 0.8689 0.8909 ... 0.8908 0.8858 0.9385\n",
       "Attributes:\n",
       "    Conventions:  CF-1.9\n",
       "    institution:  openEO platform - Geotrellis backend: 0.11.0a1\n",
       "    description:  \n",
       "    title:        >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phenology_result = xarray.load_dataset('./phenology.nc')\n",
    "phenology_result.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca184cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos = phenology_result.sos_times.median(dim=['x', 'y']).values.take(0)\n",
    "pos = phenology_result.pos_times.median(dim=['x', 'y']).values.take(0)\n",
    "eos = phenology_result.eos_times.median(dim=['x', 'y']).values.take(0)\n",
    "\n",
    "sos_date = datetime.datetime(year, 1, 1) + datetime.timedelta(days=sos)\n",
    "pos_date = datetime.datetime(year, 1, 1) + datetime.timedelta(days=pos)\n",
    "eos_date = datetime.datetime(year, 1, 1) + datetime.timedelta(days=eos)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5588ab01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
