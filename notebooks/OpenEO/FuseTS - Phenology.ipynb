{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dbe864b",
   "metadata": {},
   "source": [
    "# FuseTS - Phenology example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779c00f3",
   "metadata": {},
   "source": [
    "## Setting up the OpenEO process\n",
    "The first step includes setting up the OpenEO processing through the [OpenEO Python Client](https://open-eo.github.io/openeo-python-client/). Since the Whittaker algorithm is integrated as an [user defined process](https://open-eo.github.io/openeo-python-client/cookbook/udp_sharing.html), we can use the `datacube_from_process` function to execute the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5af56994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openeo\n",
    "import json\n",
    "import pandas as pd\n",
    "import xarray\n",
    "import matplotlib.pyplot as plt\n",
    "from openeo.rest.conversions import timeseries_json_to_pandas\n",
    "from openeo.metadata import CollectionMetadata\n",
    "from shapely.geometry import box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0e73547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated using refresh token.\n"
     ]
    }
   ],
   "source": [
    "connection = openeo.connect(\"openeo.vito.be\").authenticate_oidc()\n",
    "service = 'phenology'\n",
    "namespace = 'u:bramjanssen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "665fbf7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <script>\n",
       "    if (!window.customElements || !window.customElements.get('openeo-process')) {\n",
       "        var el = document.createElement('script');\n",
       "        el.src = \"https://cdn.jsdelivr.net/npm/@openeo/vue-components@2/assets/openeo.min.js\";\n",
       "        document.head.appendChild(el);\n",
       "\n",
       "        var font = document.createElement('font');\n",
       "        font.as = \"font\";\n",
       "        font.type = \"font/woff2\";\n",
       "        font.crossOrigin = true;\n",
       "        font.href = \"https://use.fontawesome.com/releases/v5.13.0/webfonts/fa-solid-900.woff2\"\n",
       "        document.head.appendChild(font);\n",
       "    }\n",
       "    </script>\n",
       "    <openeo-process>\n",
       "        <script type=\"application/json\">{\"show-graph\": true, \"provide-download\": false, \"process\": {\"description\": \"# Phenology\\n\\n## Description\\n\\n\\n\", \"id\": \"phenology\", \"parameters\": [{\"description\": \"A data cube.\", \"name\": \"data\", \"schema\": {\"subtype\": \"raster-cube\", \"type\": \"object\"}}], \"summary\": \"\"}}</script>\n",
       "    </openeo-process>\n",
       "    "
      ],
      "text/plain": [
       "{'description': '# Phenology\\n\\n## Description\\n\\n\\n',\n",
       " 'id': 'phenology',\n",
       " 'parameters': [{'description': 'A data cube.',\n",
       "   'name': 'data',\n",
       "   'schema': {'subtype': 'raster-cube', 'type': 'object'}}],\n",
       " 'summary': ''}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connection.describe_process(service, namespace=namespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fae8d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spat_ext = {\n",
    "          \"type\": \"Polygon\",\n",
    "          \"coordinates\": [\n",
    "            [\n",
    "              [\n",
    "                5.170012098271149,\n",
    "                51.25062964728295\n",
    "              ],\n",
    "              [\n",
    "                5.17085904378298,\n",
    "                51.24882567194015\n",
    "              ],\n",
    "              [\n",
    "                5.17857421368097,\n",
    "                51.2468515482926\n",
    "              ],\n",
    "              [\n",
    "                5.178972704726344,\n",
    "                51.24982704376254\n",
    "              ],\n",
    "              [\n",
    "                5.170012098271149,\n",
    "                51.25062964728295\n",
    "              ]\n",
    "            ]\n",
    "          ]\n",
    "        }\n",
    "temp_ext = [\"2022-01-01\",\"2022-12-31\"]\n",
    "smoothing_lambda = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f8d273",
   "metadata": {},
   "source": [
    "To begin, we calculate the base NDVI data cube. In the subsequent steps, we utilize this data cube to implement Whittaker smoothing. Finally, we compute time series for both the base NDVI and the smoothed version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7ac677b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = connection.load_collection('SENTINEL2_L2A_SENTINELHUB',\n",
    "                                spatial_extent=spat_ext,\n",
    "                                temporal_extent=temp_ext,\n",
    "                                bands=[\"B04\",\"B08\",\"SCL\"])\n",
    "base_cloudmasked = base.process(\"mask_scl_dilation\", data=base, scl_band_name=\"SCL\")\n",
    "base_ndvi = base_cloudmasked.ndvi(red=\"B04\", nir=\"B08\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62fe3c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "phenology = connection.datacube_from_process(service, namespace=f'https://openeo.vito.be/openeo/1.1/processes/{namespace}/{service}', data=base_ndvi)\n",
    "phenology_bands =  [\n",
    "        \"pos_values\",\n",
    "        \"pos_times\",\n",
    "        \"mos_values\",\n",
    "        \"vos_values\",\n",
    "        \"vos_times\",\n",
    "        \"bse_values\",\n",
    "        \"aos_values\",\n",
    "        \"sos_values\",\n",
    "        \"sos_times\",\n",
    "        \"eos_values\",\n",
    "        \"eos_times\",\n",
    "        \"los_values\",\n",
    "        \"roi_values\",\n",
    "        \"rod_values\",\n",
    "        \"lios_values\",\n",
    "        \"sios_values\",\n",
    "        \"liot_values\",\n",
    "        \"siot_values\"\n",
    "]\n",
    "metadata = CollectionMetadata({})\n",
    "metadata = metadata.add_dimension(\"bands\",phenology_bands,\"bands\")\n",
    "phenology.metadata=metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c71d6150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00 Job 'j-8af9b7e117154602bb2e0fe5469ad960': send 'start'\n",
      "0:00:27 Job 'j-8af9b7e117154602bb2e0fe5469ad960': queued (progress N/A)\n",
      "0:00:32 Job 'j-8af9b7e117154602bb2e0fe5469ad960': queued (progress N/A)\n",
      "0:00:39 Job 'j-8af9b7e117154602bb2e0fe5469ad960': queued (progress N/A)\n",
      "0:00:47 Job 'j-8af9b7e117154602bb2e0fe5469ad960': queued (progress N/A)\n",
      "0:00:57 Job 'j-8af9b7e117154602bb2e0fe5469ad960': queued (progress N/A)\n",
      "0:01:10 Job 'j-8af9b7e117154602bb2e0fe5469ad960': queued (progress N/A)\n",
      "0:01:25 Job 'j-8af9b7e117154602bb2e0fe5469ad960': queued (progress N/A)\n",
      "0:01:45 Job 'j-8af9b7e117154602bb2e0fe5469ad960': queued (progress N/A)\n",
      "0:02:09 Job 'j-8af9b7e117154602bb2e0fe5469ad960': queued (progress N/A)\n",
      "0:02:39 Job 'j-8af9b7e117154602bb2e0fe5469ad960': queued (progress N/A)\n",
      "0:03:16 Job 'j-8af9b7e117154602bb2e0fe5469ad960': running (progress N/A)\n",
      "0:04:03 Job 'j-8af9b7e117154602bb2e0fe5469ad960': running (progress N/A)\n",
      "0:05:02 Job 'j-8af9b7e117154602bb2e0fe5469ad960': error (progress N/A)\n",
      "Your batch job 'j-8af9b7e117154602bb2e0fe5469ad960' failed. Error logs:\n",
      "[{'id': '[1685542015486, 55902]', 'time': '2023-05-31T14:06:55.486Z', 'level': 'error', 'message': 'Task 0 in stage 13.0 failed 4 times; aborting job'}, {'id': '[1685542015489, 69584]', 'time': '2023-05-31T14:06:55.489Z', 'level': 'error', 'message': 'Stage error: Job aborted due to stage failure: Task 0 in stage 13.0 failed 4 times, most recent failure: Lost task 0.3 in stage 13.0 (TID 466) (epod158.vgt.vito.be executor 65): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \"/opt/spark3_4_0/python/lib/pyspark.zip/pyspark/worker.py\", line 830, in main\\n    process()\\n  File \"/opt/spark3_4_0/python/lib/pyspark.zip/pyspark/worker.py\", line 822, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/opt/spark3_4_0/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/opt/spark3_4_0/python/lib/pyspark.zip/pyspark/util.py\", line 81, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/venv/lib64/python3.8/site-packages/openeogeotrellis/utils.py\", line 50, in memory_logging_wrapper\\n    return function(*args, **kwargs)\\n  File \"/opt/venv/lib64/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/venv/lib64/python3.8/site-packages/epsel.py\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \"/opt/venv/lib64/python3.8/site-packages/openeogeotrellis/geopysparkdatacube.py\", line 521, in tile_function\\n    result_data = run_udf_code(code=udf_code, data=data)\\n  File \"/opt/venv/lib64/python3.8/site-packages/openeogeotrellis/udf.py\", line 20, in run_udf_code\\n    return openeo.udf.run_udf_code(code=code, data=data)\\n  File \"/opt/venv/lib64/python3.8/site-packages/openeo/udf/run_code.py\", line 175, in run_udf_code\\n    result_cube = func(data.get_datacube_list()[0], data.user_context)\\n  File \"<string>\", line 31, in apply_datacube\\nException: <xarray.DataArray (bands: 1, y: 256, x: 256)>\\narray([[[[  0.86516035,   0.84559095,   0.83684212, ...,   0.8380307 ,\\n            0.8328467 ,   0.75300974],\\n         [  0.854321  ,   0.84983188,   0.85719514, ...,   0.82218957,\\n            0.8026706 ,   0.73360515],\\n         [  0.84705883,   0.8509317 ,   0.85080194, ...,   0.7946493 ,\\n            0.78069353,   0.74973029],\\n         ...,\\n         [  0.87091631,   0.87016886,   0.88375056, ...,   0.90946501,\\n            0.91736746,   0.9148224 ],\\n         [  0.87137622,   0.84761906,   0.88875794, ...,   0.90996462,\\n            0.92430705,   0.9237318 ],\\n         [  0.87814277,   0.84949178,   0.89709699, ...,   0.91418684,\\n            0.93571186,   0.93280286]]],\\n\\n\\n       [[[210.        , 215.        , 205.        , ..., 165.        ,\\n          165.        , 302.        ],\\n         [165.        , 215.        , 210.        , ..., 165.        ,\\n          165.        , 225.        ],\\n         [215.        , 215.        , 215.        , ..., 165.        ,\\n...\\n                   nan,          nan],\\n         [         nan,          nan,          nan, ...,          nan,\\n                   nan,          nan],\\n         [         nan,          nan,          nan, ...,          nan,\\n                   nan,          nan]]],\\n\\n\\n       [[[         nan,          nan,          nan, ...,          nan,\\n                   nan,          nan],\\n         [         nan,          nan,          nan, ...,          nan,\\n                   nan,          nan],\\n         [         nan,          nan,          nan, ...,          nan,\\n                   nan,          nan],\\n         ...,\\n         [         nan,          nan,          nan, ...,          nan,\\n                   nan,          nan],\\n         [         nan,          nan,          nan, ...,          nan,\\n                   nan,          nan],\\n         [         nan,          nan,          nan, ...,          nan,\\n                   nan,          nan]]]])\\nCoordinates:\\n  * x        (x) float32 6.514e+05 6.514e+05 6.515e+05 ... 6.54e+05 6.54e+05\\n  * y        (y) float32 5.683e+06 5.683e+06 5.682e+06 ... 5.68e+06 5.68e+06\\n  * bands    (bands) <U11 \\'pos_values\\' \\'pos_times\\' ... \\'siot_values\\'\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:561)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:767)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:749)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:514)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:513)\\n\\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:223)\\n\\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\\n\\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1535)\\n\\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1462)\\n\\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1526)\\n\\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1349)\\n\\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:375)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:326)\\n\\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n\\nDriver stacktrace:'}, {'id': '[1685542015957, 28707]', 'time': '2023-05-31T14:06:55.957Z', 'level': 'error', 'message': 'OpenEO batch job failed: UDF Exception during Spark execution:   File \"/opt/venv/lib64/python3.8/site-packages/openeo/udf/run_code.py\", line 175, in run_udf_code\\n    result_cube = func(data.get_datacube_list()[0], data.user_context)\\n  File \"<string>\", line 31, in apply_datacube\\nException: <xarray.DataArray (bands: 1, y: 256, x: 256)>\\narray([[[[  0.86516035,   0.84559095,   0.83684212, ...,   0.8380307 ,\\n            0.8328467 ,   0.75300974],\\n         [  0.854321  ,   0.84983188,   0.85719514, ...,   0.82218957,\\n            0.8026706 ,   0.73360515],\\n         [  0.84705883,   0.8509317 ,   0.85080194, ...,   0.7946493 ,\\n            0.78069353,   0.74973029],\\n         ...,\\n         [  0.87091631,   0.87016886,   0.88375056, ...,   0.90946501,\\n            0.91736746,   0.9148224 ],\\n         [  0.87137622,   0.84761906,   0.88875794, ...,   0.90996462,\\n            0.92430705,   0.9237318 ],\\n         [  0.87814277,   0.84949178,   0.89709699, ...,   0.91418684,\\n            0.93571186,   0.93280286]]],\\n\\n\\n       [[[210.        , 215.        , 205.        , ..., 165.        ,\\n          165.        , 302.        ],\\n         [165.        , 215.        , 210.        , ..., 165.        ,\\n          165.        , 225.        ],\\n         [215.        , 215.        , 215.        , ..., 165.        ,\\n...\\n                   nan,          nan],\\n         [         nan,          nan,          nan, ...,          nan,\\n                   nan,          nan],\\n         [         nan,          nan,          nan, ...,          nan,\\n                   nan,          nan]]],\\n\\n\\n       [[[         nan,          nan,          nan, ...,          nan,\\n                   nan,          nan],\\n         [         nan,          nan,          nan, ...,          nan,\\n                   nan,          nan],\\n         [         nan,          nan,          nan, ...,          nan,\\n                   nan,          nan],\\n         ...,\\n         [         nan,          nan,          nan, ...,          nan,\\n                   nan,          na...'}, {'id': '[1685542090648, 3479345]', 'time': '2023-05-31T14:08:10.648Z', 'level': 'error', 'message': 'YARN application status reports error diagnostics: User application exited with status 1'}]\n",
      "Full logs can be inspected in an openEO (web) editor or with `connection.job('j-8af9b7e117154602bb2e0fe5469ad960').logs()`.\n"
     ]
    },
    {
     "ename": "JobFailedException",
     "evalue": "Batch job 'j-8af9b7e117154602bb2e0fe5469ad960' didn't finish successfully. Status: error (after 0:05:02).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJobFailedException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-25b4d6db83d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     'udf-dependency-archives': [\n\u001b[1;32m      3\u001b[0m          \u001b[0;34m'https://artifactory.vgt.vito.be:443/auxdata-public/ai4food/fusets_venv.zip#tmp/venv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;34m'https://artifactory.vgt.vito.be:443/auxdata-public/ai4food/fusets.zip#tmp/venv_static'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     ]\n\u001b[1;32m      6\u001b[0m })\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/openeo/rest/datacube.py\u001b[0m in \u001b[0;36mexecute_batch\u001b[0;34m(self, outputfile, out_format, print, max_poll_interval, connection_retry_interval, job_options, **format_options)\u001b[0m\n\u001b[1;32m   1990\u001b[0m         return job.run_synchronous(\n\u001b[1;32m   1991\u001b[0m             \u001b[0moutputfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1992\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_poll_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_poll_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection_retry_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconnection_retry_interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1993\u001b[0m         )\n\u001b[1;32m   1994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/openeo/rest/job.py\u001b[0m in \u001b[0;36mrun_synchronous\u001b[0;34m(self, outputfile, print, max_poll_interval, connection_retry_interval)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;34m\"\"\"Start the job, wait for it to finish and download result\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         self.start_and_wait(\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_poll_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_poll_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection_retry_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconnection_retry_interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         )\n\u001b[1;32m    207\u001b[0m         \u001b[0;31m# TODO #135 support multi file result sets too?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/openeo/rest/job.py\u001b[0m in \u001b[0;36mstart_and_wait\u001b[0;34m(self, print, max_poll_interval, connection_retry_interval, soft_error_max)\u001b[0m\n\u001b[1;32m    286\u001b[0m             raise JobFailedException(\n\u001b[1;32m    287\u001b[0m                 \u001b[0;34mf\"Batch job {self.job_id!r} didn't finish successfully. Status: {status} (after {elapsed()}).\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m                 \u001b[0mjob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m             )\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJobFailedException\u001b[0m: Batch job 'j-8af9b7e117154602bb2e0fe5469ad960' didn't finish successfully. Status: error (after 0:05:02)."
     ]
    }
   ],
   "source": [
    "phenology_job = phenology.execute_batch(out_format=\"netcdf\", title=f'FuseTS - Phenology', job_options={\n",
    "    'udf-dependency-archives': [\n",
    "         'https://artifactory.vgt.vito.be:443/auxdata-public/ai4food/fusets_venv.zip#tmp/venv',\n",
    "        'https://artifactory.vgt.vito.be:443/auxdata-public/ai4food/fusets.zip#tmp/venv_static'\n",
    "    ]\n",
    "})\n",
    "phenology_job.get_results().download_file('./phenology.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c12705c",
   "metadata": {},
   "source": [
    "## Visualising the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f7c7f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (t: 1, x: 65, y: 45)\n",
       "Coordinates:\n",
       "  * t        (t) datetime64[ns] 2020-01-01\n",
       "  * x        (x) float64 6.514e+05 6.514e+05 6.515e+05 ... 6.521e+05 6.521e+05\n",
       "  * y        (y) float64 5.68e+06 5.68e+06 5.68e+06 ... 5.68e+06 5.68e+06\n",
       "Data variables:\n",
       "    crs      |S1 b''\n",
       "    var      (t, y, x) float64 0.8873 0.8689 0.8909 ... 0.8908 0.8858 0.9385\n",
       "Attributes:\n",
       "    Conventions:  CF-1.9\n",
       "    institution:  openEO platform - Geotrellis backend: 0.11.0a1\n",
       "    description:  \n",
       "    title:        "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phenology_result = xarray.load_dataset('./phenology.nc')\n",
    "phenology_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d017ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos = phenology_result.sos_times.median(dim=['x', 'y']).values.take(0)\n",
    "pos = phenology_result.pos_times.median(dim=['x', 'y']).values.take(0)\n",
    "eos = phenology_result.eos_times.median(dim=['x', 'y']).values.take(0)\n",
    "\n",
    "sos_date = datetime.datetime(year, 1, 1) + datetime.timedelta(days=sos)\n",
    "pos_date = datetime.datetime(year, 1, 1) + datetime.timedelta(days=pos)\n",
    "eos_date = datetime.datetime(year, 1, 1) + datetime.timedelta(days=eos)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec98c19a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
