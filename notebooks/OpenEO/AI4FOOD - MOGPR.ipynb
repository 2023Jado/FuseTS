{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac819825",
   "metadata": {},
   "source": [
    "# FuseTS - MOGPR example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "642d50e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openeo\n",
    "from shapely.geometry import box\n",
    "from IPython.display import JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a401ded9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated using refresh token.\n"
     ]
    }
   ],
   "source": [
    "connection = openeo.connect(\"openeo.vito.be\").authenticate_oidc()\n",
    "service = 'mogpr'\n",
    "namespace = 'u:bramjanssen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf57e479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <script>\n",
       "    if (!window.customElements || !window.customElements.get('openeo-process')) {\n",
       "        var el = document.createElement('script');\n",
       "        el.src = \"https://cdn.jsdelivr.net/npm/@openeo/vue-components@2/assets/openeo.min.js\";\n",
       "        document.head.appendChild(el);\n",
       "\n",
       "        var font = document.createElement('font');\n",
       "        font.as = \"font\";\n",
       "        font.type = \"font/woff2\";\n",
       "        font.crossOrigin = true;\n",
       "        font.href = \"https://use.fontawesome.com/releases/v5.13.0/webfonts/fa-solid-900.woff2\"\n",
       "        document.head.appendChild(font);\n",
       "    }\n",
       "    </script>\n",
       "    <openeo-process>\n",
       "        <script type=\"application/json\">{\"show-graph\": true, \"provide-download\": false, \"process\": {\"description\": \"# Multi output gaussian process regression\\n\\n## Description\\nCompute an integrated timeseries based on multiple inputs.\\nFor instance, combine Sentinel-2 NDVI with Sentinel-1 RVI into one integrated NDVI. \\n\\n\\n## Usage\\nUsage examples for the MOGPR process.\\n\\n### Python\\nThis code example highlights the usage of the MOGPR process in an OpenEO batch job. \\nThe result of this batch job will consist of individual GeoTIFF files per date. \\nGenerating multiple GeoTIFF files as output is only possible in a batch job.  \\n```python\\nimport openeo\\n\\n# define ROI and TOI\\nextent = {\\n    \\\"west\\\": 640860,\\n    \\\"south\\\": 5676170,\\n    \\\"east\\\": 643420,\\n    \\\"north\\\": 5678730,\\n    \\\"crs\\\": \\\"EPSG:32631\\\"\\n}\\n\\nstartdate = \\\"2020-05-01\\\"\\nenddate = \\\"2020-06-01\\\"\\n\\n# get datacube\\nconnection = openeo.connect(\\\"https://openeo.cloud\\\")\\ncube = connection.datacube_from_process(\\n    \\\"MOGPR\\\", \\n    namespace=\\\"FuseTS\\\", \\n)\\njob = cube.execute_batch(out_format=\\\"GTIFF\\\")\\nresults = job.get_results()\\nresults.download_files(\\\"out\\\")  # write files to output directory\\n```\\n\\nFor small spatial and temporal extents, it is possible to get the results directly in a synchronous call:\\n```python\\ncube = connection.datacube_from_process(\\n    \\\"MOGPR\\\", \\n    namespace=\\\"FuseTS\\\" \\n)\\ncube.download(\\\"output.nc\\\", format=\\\"NetCDF\\\")\\n```\\n\\n\\n## Limitations\\nThe spatial extent is limited to a maximum size equal to a Sentinel-2 MGRS tile (100 km x 100 km).\\n\\n\\n\\n## Configuration & Resource Usage\\nRun configurations for different ROI/TOI with memory requirements and estimated run durations.\\n\\n### Synchronous calls\\nTODO: Replace with actual measurements!!!\\n\\n| Spatial extent | Run duration |\\n|----------------|--------------|\\n| 100 m x 100 m | 1 minute |\\n| 500m x 500 m | 1 minute |\\n| 1 km x 1 km | 1 minute |\\n| 5 km x 5 km | 2 minutes |\\n| 10 km x 10 km | 3 minutes |\\n| 50 km x 50 km | 9 minutes |\\n\\nThe maximum duration of a synchronous run is 15 minutes. \\nFor long running computations, you can use batch jobs. \\n\\n### Batch jobs\\nTODO: Replace with actual measurements!!!\\n\\n\\n| Spatial extent | Temporal extent | Executor memory | Run duration |\\n|----------------|-----------------|-----------------|---------|\\n| 100 m x 100 m | 1 month | default | 7 minutes |\\n| 500 m x 100 m | 1 month | default | 7 minutes |\\n| 1 km x 1 km | 1 month | default | 7 minutes |\\n| 5 km x 5 km | 1 month | default | 10 minutes |\\n| 10 km x 10 km | 1 month | default | 11 minutes |\\n| 50 km x 50 km | 1 month | 6 GB | 20 minutes |\\n| 100 km x 100 km | 1 month | 7 GB | 34 minutes |\\n| 100m x 100 m | 7 months | default | 10 minutes |\\n| 500 m x 500 m | 7 months | default | 10 minutes |\\n| 1 km x 1 km | 7 months | default | 14 minutes |\\n| 5 km x 5 km | 7 months | default | 14 minutes |\\n| 10 km x 10 km | 7 months | default | 19 minutes |\\n| 50 km x 50 km | 7 months | 6 GB | 45 minutes |\\n| 100 km x 100 km | 7 months | 8 GB | 65 minutes |\\n\\nThe executor memory defaults to 5 GB. You can increase the executor memory by specifying it as a job option, eg:\\n```python\\njob = cube.execute_batch(out_format=\\\"GTIFF\\\", job_options={\\\"executor-memory\\\": \\\"7g\\\"})\\n```\", \"id\": \"mogpr\", \"parameters\": [{\"description\": \"A data cube.\", \"name\": \"data\", \"schema\": {\"subtype\": \"raster-cube\", \"type\": \"object\"}}], \"summary\": \"Integrates timeseries in data cube using multi-output gaussian process regression.\"}}</script>\n",
       "    </openeo-process>\n",
       "    "
      ],
      "text/plain": [
       "{'description': '# Multi output gaussian process regression\\n\\n## Description\\nCompute an integrated timeseries based on multiple inputs.\\nFor instance, combine Sentinel-2 NDVI with Sentinel-1 RVI into one integrated NDVI. \\n\\n\\n## Usage\\nUsage examples for the MOGPR process.\\n\\n### Python\\nThis code example highlights the usage of the MOGPR process in an OpenEO batch job. \\nThe result of this batch job will consist of individual GeoTIFF files per date. \\nGenerating multiple GeoTIFF files as output is only possible in a batch job.  \\n```python\\nimport openeo\\n\\n# define ROI and TOI\\nextent = {\\n    \"west\": 640860,\\n    \"south\": 5676170,\\n    \"east\": 643420,\\n    \"north\": 5678730,\\n    \"crs\": \"EPSG:32631\"\\n}\\n\\nstartdate = \"2020-05-01\"\\nenddate = \"2020-06-01\"\\n\\n# get datacube\\nconnection = openeo.connect(\"https://openeo.cloud\")\\ncube = connection.datacube_from_process(\\n    \"MOGPR\", \\n    namespace=\"FuseTS\", \\n)\\njob = cube.execute_batch(out_format=\"GTIFF\")\\nresults = job.get_results()\\nresults.download_files(\"out\")  # write files to output directory\\n```\\n\\nFor small spatial and temporal extents, it is possible to get the results directly in a synchronous call:\\n```python\\ncube = connection.datacube_from_process(\\n    \"MOGPR\", \\n    namespace=\"FuseTS\" \\n)\\ncube.download(\"output.nc\", format=\"NetCDF\")\\n```\\n\\n\\n## Limitations\\nThe spatial extent is limited to a maximum size equal to a Sentinel-2 MGRS tile (100 km x 100 km).\\n\\n\\n\\n## Configuration & Resource Usage\\nRun configurations for different ROI/TOI with memory requirements and estimated run durations.\\n\\n### Synchronous calls\\nTODO: Replace with actual measurements!!!\\n\\n| Spatial extent | Run duration |\\n|----------------|--------------|\\n| 100 m x 100 m | 1 minute |\\n| 500m x 500 m | 1 minute |\\n| 1 km x 1 km | 1 minute |\\n| 5 km x 5 km | 2 minutes |\\n| 10 km x 10 km | 3 minutes |\\n| 50 km x 50 km | 9 minutes |\\n\\nThe maximum duration of a synchronous run is 15 minutes. \\nFor long running computations, you can use batch jobs. \\n\\n### Batch jobs\\nTODO: Replace with actual measurements!!!\\n\\n\\n| Spatial extent | Temporal extent | Executor memory | Run duration |\\n|----------------|-----------------|-----------------|---------|\\n| 100 m x 100 m | 1 month | default | 7 minutes |\\n| 500 m x 100 m | 1 month | default | 7 minutes |\\n| 1 km x 1 km | 1 month | default | 7 minutes |\\n| 5 km x 5 km | 1 month | default | 10 minutes |\\n| 10 km x 10 km | 1 month | default | 11 minutes |\\n| 50 km x 50 km | 1 month | 6 GB | 20 minutes |\\n| 100 km x 100 km | 1 month | 7 GB | 34 minutes |\\n| 100m x 100 m | 7 months | default | 10 minutes |\\n| 500 m x 500 m | 7 months | default | 10 minutes |\\n| 1 km x 1 km | 7 months | default | 14 minutes |\\n| 5 km x 5 km | 7 months | default | 14 minutes |\\n| 10 km x 10 km | 7 months | default | 19 minutes |\\n| 50 km x 50 km | 7 months | 6 GB | 45 minutes |\\n| 100 km x 100 km | 7 months | 8 GB | 65 minutes |\\n\\nThe executor memory defaults to 5 GB. You can increase the executor memory by specifying it as a job option, eg:\\n```python\\njob = cube.execute_batch(out_format=\"GTIFF\", job_options={\"executor-memory\": \"7g\"})\\n```',\n",
       " 'id': 'mogpr',\n",
       " 'parameters': [{'description': 'A data cube.',\n",
       "   'name': 'data',\n",
       "   'schema': {'subtype': 'raster-cube', 'type': 'object'}}],\n",
       " 'summary': 'Integrates timeseries in data cube using multi-output gaussian process regression.'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connection.describe_process(service, namespace=namespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f38f9500",
   "metadata": {},
   "outputs": [],
   "source": [
    "spat_ext = {\n",
    "          \"type\": \"Polygon\",\n",
    "          \"coordinates\": [\n",
    "            [\n",
    "              [\n",
    "                5.170012098271149,\n",
    "                51.25062964728295\n",
    "              ],\n",
    "              [\n",
    "                5.17085904378298,\n",
    "                51.24882567194015\n",
    "              ],\n",
    "              [\n",
    "                5.17857421368097,\n",
    "                51.2468515482926\n",
    "              ],\n",
    "              [\n",
    "                5.178972704726344,\n",
    "                51.24982704376254\n",
    "              ],\n",
    "              [\n",
    "                5.170012098271149,\n",
    "                51.25062964728295\n",
    "              ]\n",
    "            ]\n",
    "          ]\n",
    "        }\n",
    "temp_ext = [\"2023-01-01\",\"2023-01-31\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a88e88c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = connection.load_collection('SENTINEL2_L2A_SENTINELHUB',\n",
    "                                spatial_extent=spat_ext,\n",
    "                                temporal_extent=temp_ext,\n",
    "                                bands=[\"B04\",\"B08\",\"SCL\"])\n",
    "base_cloudmasked = base.process(\"mask_scl_dilation\", data=base, scl_band_name=\"SCL\")\n",
    "base_ndvi = base_cloudmasked.ndvi(red=\"B04\", nir=\"B08\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b83a276c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserDeprecationWarning: Call to deprecated method polygonal_mean_timeseries. (Use `aggregate_spatial` with reducer ``'mean'``.) -- Deprecated since version 0.10.0.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "mogpr = connection.datacube_from_process(service, namespace=f'https://openeo.vito.be/openeo/1.1/processes/{namespace}/{service}', data=base_ndvi)\n",
    "mogpr = mogpr.polygonal_mean_timeseries(spat_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23fb58a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00 Job 'j-81a425301b5b4fb68c9ce27e54027b55': send 'start'\n",
      "0:00:31 Job 'j-81a425301b5b4fb68c9ce27e54027b55': queued (progress N/A)\n",
      "0:00:36 Job 'j-81a425301b5b4fb68c9ce27e54027b55': queued (progress N/A)\n",
      "0:00:43 Job 'j-81a425301b5b4fb68c9ce27e54027b55': queued (progress N/A)\n",
      "0:00:51 Job 'j-81a425301b5b4fb68c9ce27e54027b55': queued (progress N/A)\n",
      "0:01:02 Job 'j-81a425301b5b4fb68c9ce27e54027b55': queued (progress N/A)\n",
      "0:01:14 Job 'j-81a425301b5b4fb68c9ce27e54027b55': queued (progress N/A)\n",
      "0:01:30 Job 'j-81a425301b5b4fb68c9ce27e54027b55': queued (progress N/A)\n",
      "0:01:49 Job 'j-81a425301b5b4fb68c9ce27e54027b55': queued (progress N/A)\n",
      "0:02:13 Job 'j-81a425301b5b4fb68c9ce27e54027b55': queued (progress N/A)\n",
      "0:02:43 Job 'j-81a425301b5b4fb68c9ce27e54027b55': queued (progress N/A)\n",
      "0:03:20 Job 'j-81a425301b5b4fb68c9ce27e54027b55': error (progress N/A)\n",
      "Your batch job 'j-81a425301b5b4fb68c9ce27e54027b55' failed. Error logs:\n",
      "[{'id': '[1682405618176, 618]', 'time': '2023-04-25T06:53:38.176Z', 'level': 'error', 'message': 'Exception in task 0.0 in stage 16.0 (TID 57)'}, {'id': '[1682405619657, 618]', 'time': '2023-04-25T06:53:39.657Z', 'level': 'error', 'message': 'Exception in task 0.1 in stage 16.0 (TID 58)'}, {'id': '[1682405628561, 0]', 'time': '2023-04-25T06:53:48.561Z', 'level': 'error', 'message': 'Exception in task 0.2 in stage 16.0 (TID 59)'}, {'id': '[1682405636027, 0]', 'time': '2023-04-25T06:53:56.027Z', 'level': 'error', 'message': 'Exception in task 0.3 in stage 16.0 (TID 60)'}, {'id': '[1682405636097, 41230]', 'time': '2023-04-25T06:53:56.097Z', 'level': 'error', 'message': 'Aborting job 8ab396fc-2a05-4547-bab0-1a7521f10819.'}, {'id': '[1682405636832, 29795]', 'time': '2023-04-25T06:53:56.832Z', 'level': 'error', 'message': 'OpenEO batch job failed: UDF Exception during Spark execution:   File \"<string>\", line 29, in apply_datacube\\n  File \"tmp/venv_static/fusets/mogpr.py\", line 129, in fit_transform\\n    return mogpr(X)\\n  File \"tmp/venv_static/fusets/mogpr.py\", line 173, in mogpr\\n    result = xarray.apply_ufunc(callback, array.to_array(dim=\"variable\"), input_core_dims=[[\"variable\",time_dimension]], output_core_dims=[[\"variable\",output_time_dimension]],vectorize=True)\\n  File \"/opt/venv/lib64/python3.8/site-packages/xarray/core/common.py\", line 228, in __getattr__\\n    raise AttributeError(\\nAttributeError: \\'DataArray\\' object has no attribute \\'to_array\\''}]\n",
      "Full logs can be inspected in an openEO (web) editor or with `connection.job('j-81a425301b5b4fb68c9ce27e54027b55').logs()`.\n"
     ]
    },
    {
     "ename": "JobFailedException",
     "evalue": "Batch job 'j-81a425301b5b4fb68c9ce27e54027b55' didn't finish successfully. Status: error (after 0:03:21).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJobFailedException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-40dbf5dc5378>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;34m'https://artifactory.vgt.vito.be:443/auxdata-public/ai4food/fusets.zip#tmp/venv_static'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     ],\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;34m'executor-memory'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'7g'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m })\n\u001b[1;32m      8\u001b[0m \u001b[0mmogpr_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./mogpr.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/openeo/rest/datacube.py\u001b[0m in \u001b[0;36mexecute_batch\u001b[0;34m(self, outputfile, out_format, print, max_poll_interval, connection_retry_interval, job_options, **format_options)\u001b[0m\n\u001b[1;32m   1909\u001b[0m         return job.run_synchronous(\n\u001b[1;32m   1910\u001b[0m             \u001b[0moutputfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_poll_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_poll_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection_retry_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconnection_retry_interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m         )\n\u001b[1;32m   1913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/openeo/rest/job.py\u001b[0m in \u001b[0;36mrun_synchronous\u001b[0;34m(self, outputfile, print, max_poll_interval, connection_retry_interval)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;34m\"\"\"Start the job, wait for it to finish and download result\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         self.start_and_wait(\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_poll_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_poll_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection_retry_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconnection_retry_interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         )\n\u001b[1;32m    189\u001b[0m         \u001b[0;31m# TODO #135 support multi file result sets too?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/openeo/rest/job.py\u001b[0m in \u001b[0;36mstart_and_wait\u001b[0;34m(self, print, max_poll_interval, connection_retry_interval, soft_error_max)\u001b[0m\n\u001b[1;32m    268\u001b[0m             raise JobFailedException(\n\u001b[1;32m    269\u001b[0m                 \u001b[0;34mf\"Batch job {self.job_id!r} didn't finish successfully. Status: {status} (after {elapsed()}).\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m                 \u001b[0mjob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m             )\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJobFailedException\u001b[0m: Batch job 'j-81a425301b5b4fb68c9ce27e54027b55' didn't finish successfully. Status: error (after 0:03:21)."
     ]
    }
   ],
   "source": [
    "mogpr_job = mogpr.execute_batch(out_format=\"json\", title=f'AI4FOOD - MOGPR', job_options={\n",
    "    'udf-dependency-archives': [\n",
    "         'https://artifactory.vgt.vito.be:443/auxdata-public/ai4food/fusets_venv.zip#tmp/venv',\n",
    "        'https://artifactory.vgt.vito.be:443/auxdata-public/ai4food/fusets.zip#tmp/venv_static'\n",
    "    ],\n",
    "    'executor-memory': '7g'\n",
    "})\n",
    "mogpr_job.get_results().download_file('./mogpr.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1359b6ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
