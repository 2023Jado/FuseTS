{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf897840",
   "metadata": {},
   "source": [
    "# FuseTS - MOGPR\n",
    "\n",
    "This Jupyter Notebook implements the MOGPR service, which is part of the FuseTS toolbox. The purpose of this notebook is to showcase the utilization of openEO to execute the MOGPR service for a specific area of interest (AOI).\n",
    "\n",
    "The MOGPR service is designed to enable multi-output regression analysis using Gaussian Process Regression (GPR) on geospatial data. It provides a powerful tool for understanding and predicting spatio-temporal phenomena by filling gaps based on other indicators that are correlated with each other.\n",
    "\n",
    "Within this notebook, you will find the necessary code and instructions to retrieve relevant geospatial data for your AOI using openEO. The openEO framework facilitates seamless integration and processing of geospatial data, making it an ideal environment for executing the MOGPR service.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4ad373",
   "metadata": {},
   "source": [
    "## Setting up the OpenEO process\n",
    "The first step includes setting up the OpenEO processing through the [OpenEO Python Client](https://open-eo.github.io/openeo-python-client/). Since the MOGPR algorithm is integrated as an [user defined process](https://open-eo.github.io/openeo-python-client/cookbook/udp_sharing.html), we can use the `datacube_from_process` function to execute the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a4361eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openeo\n",
    "from shapely.geometry import box\n",
    "from IPython.display import JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01a15b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated using refresh token.\n"
     ]
    }
   ],
   "source": [
    "connection = openeo.connect(\"openeo.vito.be\").authenticate_oidc()\n",
    "service = 'mogpr'\n",
    "namespace = 'u:bramjanssen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04071370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <script>\n",
       "    if (!window.customElements || !window.customElements.get('openeo-process')) {\n",
       "        var el = document.createElement('script');\n",
       "        el.src = \"https://cdn.jsdelivr.net/npm/@openeo/vue-components@2/assets/openeo.min.js\";\n",
       "        document.head.appendChild(el);\n",
       "\n",
       "        var font = document.createElement('font');\n",
       "        font.as = \"font\";\n",
       "        font.type = \"font/woff2\";\n",
       "        font.crossOrigin = true;\n",
       "        font.href = \"https://use.fontawesome.com/releases/v5.13.0/webfonts/fa-solid-900.woff2\"\n",
       "        document.head.appendChild(font);\n",
       "    }\n",
       "    </script>\n",
       "    <openeo-process>\n",
       "        <script type=\"application/json\">{\"show-graph\": true, \"provide-download\": false, \"process\": {\"description\": \"# Multi output gaussian process regression\\n\\n## Description\\nCompute an integrated timeseries based on multiple inputs.\\nFor instance, combine Sentinel-2 NDVI with Sentinel-1 RVI into one integrated NDVI. \\n\\n\\n## Usage\\nUsage examples for the MOGPR process.\\n\\n### Python\\nThis code example highlights the usage of the MOGPR process in an OpenEO batch job. \\nThe result of this batch job will consist of individual GeoTIFF files per date. \\nGenerating multiple GeoTIFF files as output is only possible in a batch job.  \\n```python\\nimport openeo\\n\\n# define ROI and TOI\\nextent = {\\n    \\\"west\\\": 640860,\\n    \\\"south\\\": 5676170,\\n    \\\"east\\\": 643420,\\n    \\\"north\\\": 5678730,\\n    \\\"crs\\\": \\\"EPSG:32631\\\"\\n}\\n\\nstartdate = \\\"2020-05-01\\\"\\nenddate = \\\"2020-06-01\\\"\\n\\n# get datacube\\nconnection = openeo.connect(\\\"https://openeo.cloud\\\")\\ncube = connection.datacube_from_process(\\n    \\\"MOGPR\\\", \\n    namespace=\\\"FuseTS\\\", \\n)\\njob = cube.execute_batch(out_format=\\\"GTIFF\\\")\\nresults = job.get_results()\\nresults.download_files(\\\"out\\\")  # write files to output directory\\n```\\n\\nFor small spatial and temporal extents, it is possible to get the results directly in a synchronous call:\\n```python\\ncube = connection.datacube_from_process(\\n    \\\"MOGPR\\\", \\n    namespace=\\\"FuseTS\\\" \\n)\\ncube.download(\\\"output.nc\\\", format=\\\"NetCDF\\\")\\n```\\n\\n\\n## Limitations\\nThe spatial extent is limited to a maximum size equal to a Sentinel-2 MGRS tile (100 km x 100 km).\\n\\n\\n\\n## Configuration & Resource Usage\\nRun configurations for different ROI/TOI with memory requirements and estimated run durations.\\n\\n### Synchronous calls\\nTODO: Replace with actual measurements!!!\\n\\n| Spatial extent | Run duration |\\n|----------------|--------------|\\n| 100 m x 100 m | 1 minute |\\n| 500m x 500 m | 1 minute |\\n| 1 km x 1 km | 1 minute |\\n| 5 km x 5 km | 2 minutes |\\n| 10 km x 10 km | 3 minutes |\\n| 50 km x 50 km | 9 minutes |\\n\\nThe maximum duration of a synchronous run is 15 minutes. \\nFor long running computations, you can use batch jobs. \\n\\n### Batch jobs\\nTODO: Replace with actual measurements!!!\\n\\n\\n| Spatial extent | Temporal extent | Executor memory | Run duration |\\n|----------------|-----------------|-----------------|---------|\\n| 100 m x 100 m | 1 month | default | 7 minutes |\\n| 500 m x 100 m | 1 month | default | 7 minutes |\\n| 1 km x 1 km | 1 month | default | 7 minutes |\\n| 5 km x 5 km | 1 month | default | 10 minutes |\\n| 10 km x 10 km | 1 month | default | 11 minutes |\\n| 50 km x 50 km | 1 month | 6 GB | 20 minutes |\\n| 100 km x 100 km | 1 month | 7 GB | 34 minutes |\\n| 100m x 100 m | 7 months | default | 10 minutes |\\n| 500 m x 500 m | 7 months | default | 10 minutes |\\n| 1 km x 1 km | 7 months | default | 14 minutes |\\n| 5 km x 5 km | 7 months | default | 14 minutes |\\n| 10 km x 10 km | 7 months | default | 19 minutes |\\n| 50 km x 50 km | 7 months | 6 GB | 45 minutes |\\n| 100 km x 100 km | 7 months | 8 GB | 65 minutes |\\n\\nThe executor memory defaults to 5 GB. You can increase the executor memory by specifying it as a job option, eg:\\n```python\\njob = cube.execute_batch(out_format=\\\"GTIFF\\\", job_options={\\\"executor-memory\\\": \\\"7g\\\"})\\n```\", \"id\": \"mogpr\", \"parameters\": [{\"description\": \"A data cube.\", \"name\": \"data\", \"schema\": {\"subtype\": \"raster-cube\", \"type\": \"object\"}}], \"summary\": \"Integrates timeseries in data cube using multi-output gaussian process regression.\"}}</script>\n",
       "    </openeo-process>\n",
       "    "
      ],
      "text/plain": [
       "{'description': '# Multi output gaussian process regression\\n\\n## Description\\nCompute an integrated timeseries based on multiple inputs.\\nFor instance, combine Sentinel-2 NDVI with Sentinel-1 RVI into one integrated NDVI. \\n\\n\\n## Usage\\nUsage examples for the MOGPR process.\\n\\n### Python\\nThis code example highlights the usage of the MOGPR process in an OpenEO batch job. \\nThe result of this batch job will consist of individual GeoTIFF files per date. \\nGenerating multiple GeoTIFF files as output is only possible in a batch job.  \\n```python\\nimport openeo\\n\\n# define ROI and TOI\\nextent = {\\n    \"west\": 640860,\\n    \"south\": 5676170,\\n    \"east\": 643420,\\n    \"north\": 5678730,\\n    \"crs\": \"EPSG:32631\"\\n}\\n\\nstartdate = \"2020-05-01\"\\nenddate = \"2020-06-01\"\\n\\n# get datacube\\nconnection = openeo.connect(\"https://openeo.cloud\")\\ncube = connection.datacube_from_process(\\n    \"MOGPR\", \\n    namespace=\"FuseTS\", \\n)\\njob = cube.execute_batch(out_format=\"GTIFF\")\\nresults = job.get_results()\\nresults.download_files(\"out\")  # write files to output directory\\n```\\n\\nFor small spatial and temporal extents, it is possible to get the results directly in a synchronous call:\\n```python\\ncube = connection.datacube_from_process(\\n    \"MOGPR\", \\n    namespace=\"FuseTS\" \\n)\\ncube.download(\"output.nc\", format=\"NetCDF\")\\n```\\n\\n\\n## Limitations\\nThe spatial extent is limited to a maximum size equal to a Sentinel-2 MGRS tile (100 km x 100 km).\\n\\n\\n\\n## Configuration & Resource Usage\\nRun configurations for different ROI/TOI with memory requirements and estimated run durations.\\n\\n### Synchronous calls\\nTODO: Replace with actual measurements!!!\\n\\n| Spatial extent | Run duration |\\n|----------------|--------------|\\n| 100 m x 100 m | 1 minute |\\n| 500m x 500 m | 1 minute |\\n| 1 km x 1 km | 1 minute |\\n| 5 km x 5 km | 2 minutes |\\n| 10 km x 10 km | 3 minutes |\\n| 50 km x 50 km | 9 minutes |\\n\\nThe maximum duration of a synchronous run is 15 minutes. \\nFor long running computations, you can use batch jobs. \\n\\n### Batch jobs\\nTODO: Replace with actual measurements!!!\\n\\n\\n| Spatial extent | Temporal extent | Executor memory | Run duration |\\n|----------------|-----------------|-----------------|---------|\\n| 100 m x 100 m | 1 month | default | 7 minutes |\\n| 500 m x 100 m | 1 month | default | 7 minutes |\\n| 1 km x 1 km | 1 month | default | 7 minutes |\\n| 5 km x 5 km | 1 month | default | 10 minutes |\\n| 10 km x 10 km | 1 month | default | 11 minutes |\\n| 50 km x 50 km | 1 month | 6 GB | 20 minutes |\\n| 100 km x 100 km | 1 month | 7 GB | 34 minutes |\\n| 100m x 100 m | 7 months | default | 10 minutes |\\n| 500 m x 500 m | 7 months | default | 10 minutes |\\n| 1 km x 1 km | 7 months | default | 14 minutes |\\n| 5 km x 5 km | 7 months | default | 14 minutes |\\n| 10 km x 10 km | 7 months | default | 19 minutes |\\n| 50 km x 50 km | 7 months | 6 GB | 45 minutes |\\n| 100 km x 100 km | 7 months | 8 GB | 65 minutes |\\n\\nThe executor memory defaults to 5 GB. You can increase the executor memory by specifying it as a job option, eg:\\n```python\\njob = cube.execute_batch(out_format=\"GTIFF\", job_options={\"executor-memory\": \"7g\"})\\n```',\n",
       " 'id': 'mogpr',\n",
       " 'parameters': [{'description': 'A data cube.',\n",
       "   'name': 'data',\n",
       "   'schema': {'subtype': 'raster-cube', 'type': 'object'}}],\n",
       " 'summary': 'Integrates timeseries in data cube using multi-output gaussian process regression.'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connection.describe_process(service, namespace=namespace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319adc5e",
   "metadata": {},
   "source": [
    "### Use `datacube_from_process` to get initial DataCube\n",
    "Get output datacube from process by passing in the process parameters:\n",
    "**Mandatory**\n",
    "- `data`: The initial datacube upon which to execute the service\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7061fbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spat_ext = {\n",
    "          \"type\": \"Polygon\",\n",
    "          \"coordinates\": [\n",
    "            [\n",
    "              [\n",
    "                5.170012098271149,\n",
    "                51.25062964728295\n",
    "              ],\n",
    "              [\n",
    "                5.17085904378298,\n",
    "                51.24882567194015\n",
    "              ],\n",
    "              [\n",
    "                5.17857421368097,\n",
    "                51.2468515482926\n",
    "              ],\n",
    "              [\n",
    "                5.178972704726344,\n",
    "                51.24982704376254\n",
    "              ],\n",
    "              [\n",
    "                5.170012098271149,\n",
    "                51.25062964728295\n",
    "              ]\n",
    "            ]\n",
    "          ]\n",
    "        }\n",
    "temp_ext = [\"2023-01-01\",\"2023-01-31\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "948fd2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = connection.load_collection('SENTINEL2_L2A_SENTINELHUB',\n",
    "                                spatial_extent=spat_ext,\n",
    "                                temporal_extent=temp_ext,\n",
    "                                bands=[\"B04\",\"B08\",\"SCL\"])\n",
    "base_cloudmasked = base.process(\"mask_scl_dilation\", data=base, scl_band_name=\"SCL\")\n",
    "base_ndvi = base_cloudmasked.ndvi(red=\"B04\", nir=\"B08\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64c506d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mogpr = connection.datacube_from_process(service, namespace=f'https://openeo.vito.be/openeo/1.1/processes/{namespace}/{service}', data=base_ndvi)\n",
    "mogpr = mogpr.aggregate_spatial(spat_ext, reducer='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1cb24e",
   "metadata": {},
   "source": [
    "### Execute job and download result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46c190ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00 Job 'j-8b2ada7a1e9242aea6bbf91f7e1fc15e': send 'start'\n",
      "0:00:30 Job 'j-8b2ada7a1e9242aea6bbf91f7e1fc15e': queued (progress N/A)\n",
      "0:00:39 Job 'j-8b2ada7a1e9242aea6bbf91f7e1fc15e': queued (progress N/A)\n",
      "0:00:45 Job 'j-8b2ada7a1e9242aea6bbf91f7e1fc15e': queued (progress N/A)\n",
      "0:00:53 Job 'j-8b2ada7a1e9242aea6bbf91f7e1fc15e': queued (progress N/A)\n",
      "0:01:03 Job 'j-8b2ada7a1e9242aea6bbf91f7e1fc15e': queued (progress N/A)\n",
      "0:01:16 Job 'j-8b2ada7a1e9242aea6bbf91f7e1fc15e': queued (progress N/A)\n",
      "0:01:31 Job 'j-8b2ada7a1e9242aea6bbf91f7e1fc15e': queued (progress N/A)\n",
      "0:01:51 Job 'j-8b2ada7a1e9242aea6bbf91f7e1fc15e': queued (progress N/A)\n",
      "0:02:26 Job 'j-8b2ada7a1e9242aea6bbf91f7e1fc15e': queued (progress N/A)\n",
      "0:02:56 Job 'j-8b2ada7a1e9242aea6bbf91f7e1fc15e': running (progress N/A)\n",
      "0:03:34 Job 'j-8b2ada7a1e9242aea6bbf91f7e1fc15e': running (progress N/A)\n",
      "0:04:23 Job 'j-8b2ada7a1e9242aea6bbf91f7e1fc15e': running (progress N/A)\n",
      "0:05:22 Job 'j-8b2ada7a1e9242aea6bbf91f7e1fc15e': error (progress N/A)\n",
      "Your batch job 'j-8b2ada7a1e9242aea6bbf91f7e1fc15e' failed. Error logs:\n",
      "[{'id': '[1685086219681, 69764]', 'time': '2023-05-26T07:30:19.681Z', 'level': 'error', 'message': 'Task 0 in stage 15.0 failed 4 times; aborting job'}, {'id': '[1685086219691, 70099]', 'time': '2023-05-26T07:30:19.691Z', 'level': 'error', 'message': 'Stage error: Job aborted due to stage failure: Task 0 in stage 15.0 failed 4 times, most recent failure: Lost task 0.3 in stage 15.0 (TID 60) (epod156.vgt.vito.be executor 13): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\\n  File \"/opt/spark3_4_0/python/lib/pyspark.zip/pyspark/worker.py\", line 830, in main\\n    process()\\n  File \"/opt/spark3_4_0/python/lib/pyspark.zip/pyspark/worker.py\", line 822, in process\\n    serializer.dump_stream(out_iter, outfile)\\n  File \"/opt/spark3_4_0/python/lib/pyspark.zip/pyspark/serializers.py\", line 146, in dump_stream\\n    for obj in iterator:\\n  File \"/opt/spark3_4_0/python/lib/pyspark.zip/pyspark/util.py\", line 81, in wrapper\\n    return f(*args, **kwargs)\\n  File \"/opt/venv/lib64/python3.8/site-packages/openeogeotrellis/utils.py\", line 50, in memory_logging_wrapper\\n    return function(*args, **kwargs)\\n  File \"/opt/venv/lib64/python3.8/site-packages/epsel.py\", line 44, in wrapper\\n    return _FUNCTION_POINTERS[key](*args, **kwargs)\\n  File \"/opt/venv/lib64/python3.8/site-packages/epsel.py\", line 37, in first_time\\n    return f(*args, **kwargs)\\n  File \"/opt/venv/lib64/python3.8/site-packages/openeogeotrellis/geopysparkdatacube.py\", line 521, in tile_function\\n    result_data = run_udf_code(code=udf_code, data=data)\\n  File \"/opt/venv/lib64/python3.8/site-packages/openeogeotrellis/udf.py\", line 20, in run_udf_code\\n    return openeo.udf.run_udf_code(code=code, data=data)\\n  File \"/opt/venv/lib64/python3.8/site-packages/openeo/udf/run_code.py\", line 175, in run_udf_code\\n    result_cube = func(data.get_datacube_list()[0], data.user_context)\\n  File \"<string>\", line 29, in apply_datacube\\n  File \"tmp/venv_static/fusets/mogpr.py\", line 129, in fit_transform\\n    return mogpr(X)\\n  File \"tmp/venv_static/fusets/mogpr.py\", line 173, in mogpr\\n    result = xarray.apply_ufunc(callback, array.to_array(dim=\"variable\"), input_core_dims=[[\"variable\",time_dimension]], output_core_dims=[[\"variable\",output_time_dimension]],vectorize=True)\\n  File \"/opt/venv/lib64/python3.8/site-packages/xarray/core/computation.py\", line 1128, in apply_ufunc\\n    return apply_dataarray_vfunc(\\n  File \"/opt/venv/lib64/python3.8/site-packages/xarray/core/computation.py\", line 271, in apply_dataarray_vfunc\\n    result_var = func(*data_vars)\\n  File \"/opt/venv/lib64/python3.8/site-packages/xarray/core/computation.py\", line 724, in apply_variable_ufunc\\n    result_data = func(*input_data)\\n  File \"/opt/venv/lib64/python3.8/site-packages/numpy/lib/function_base.py\", line 2304, in __call__\\n    return self._vectorize_call(func=func, args=vargs)\\n  File \"/opt/venv/lib64/python3.8/site-packages/numpy/lib/function_base.py\", line 2378, in _vectorize_call\\n    res = self._vectorize_call_with_signature(func, args)\\n  File \"/opt/venv/lib64/python3.8/site-packages/numpy/lib/function_base.py\", line 2418, in _vectorize_call_with_signature\\n    results = func(*(arg[index] for arg in args))\\n  File \"tmp/venv_static/fusets/mogpr.py\", line 167, in callback\\n    out_mean, out_std, out_qflag, out_model = mogpr_1D(timeseries, list([np.array(dates_np) for i in timeseries]), 0, output_timevec=output_timevec, nt=1, trained_model=None)\\n  File \"tmp/venv_static/fusets/mogpr.py\", line 317, in mogpr_1D\\n    from GPy.kern import Matern32\\n  File \"tmp/venv/GPy/__init__.py\", line 15, in <module>\\n    from . import plotting\\n  File \"tmp/venv/GPy/plotting/__init__.py\", line 156, in <module>\\n    change_plotting_library(lib)\\n  File \"tmp/venv/GPy/plotting/__init__.py\", line 34, in change_plotting_library\\n    import matplotlib\\n  File \"tmp/venv/matplotlib/__init__.py\", line 131, in <module>\\n    from . import _api, _version, cbook, _docstring, rcsetup\\n  File \"tmp/venv/matplotlib/cbook/__init__.py\", line 30, in <module>\\n    from matplotlib import _api, _c_internal_utils\\nImportError: cannot import name \\'_c_internal_utils\\' from partially initialized module \\'matplotlib\\' (most likely due to a circular import) (tmp/venv/matplotlib/__init__.py)\\n\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:561)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:767)\\n\\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:749)\\n\\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:514)\\n\\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:223)\\n\\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsBytes(MemoryStore.scala:352)\\n\\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1552)\\n\\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1462)\\n\\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1526)\\n\\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1349)\\n\\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:375)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:326)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:101)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n\\nDriver stacktrace:'}, {'id': '[1685086221246, 32735]', 'time': '2023-05-26T07:30:21.246Z', 'level': 'error', 'message': 'OpenEO batch job failed: UDF Exception during Spark execution:   File \"/opt/venv/lib64/python3.8/site-packages/openeo/udf/run_code.py\", line 175, in run_udf_code\\n    result_cube = func(data.get_datacube_list()[0], data.user_context)\\n  File \"<string>\", line 29, in apply_datacube\\n  File \"tmp/venv_static/fusets/mogpr.py\", line 129, in fit_transform\\n    return mogpr(X)\\n  File \"tmp/venv_static/fusets/mogpr.py\", line 173, in mogpr\\n    result = xarray.apply_ufunc(callback, array.to_array(dim=\"variable\"), input_core_dims=[[\"variable\",time_dimension]], output_core_dims=[[\"variable\",output_time_dimension]],vectorize=True)\\n  File \"/opt/venv/lib64/python3.8/site-packages/xarray/core/computation.py\", line 1128, in apply_ufunc\\n    return apply_dataarray_vfunc(\\n  File \"/opt/venv/lib64/python3.8/site-packages/xarray/core/computation.py\", line 271, in apply_dataarray_vfunc\\n    result_var = func(*data_vars)\\n  File \"/opt/venv/lib64/python3.8/site-packages/xarray/core/computation.py\", line 724, in apply_variable_ufunc\\n    result_data = func(*input_data)\\n  File \"/opt/venv/lib64/python3.8/site-packages/numpy/lib/function_base.py\", line 2304, in __call__\\n    return self._vectorize_call(func=func, args=vargs)\\n  File \"/opt/venv/lib64/python3.8/site-packages/numpy/lib/function_base.py\", line 2378, in _vectorize_call\\n    res = self._vectorize_call_with_signature(func, args)\\n  File \"/opt/venv/lib64/python3.8/site-packages/numpy/lib/function_base.py\", line 2418, in _vectorize_call_with_signature\\n    results = func(*(arg[index] for arg in args))\\n  File \"tmp/venv_static/fusets/mogpr.py\", line 167, in callback\\n    out_mean, out_std, out_qflag, out_model = mogpr_1D(timeseries, list([np.array(dates_np) for i in timeseries]), 0, output_timevec=output_timevec, nt=1, trained_model=None)\\n  File \"tmp/venv_static/fusets/mogpr.py\", line 317, in mogpr_1D\\n    from GPy.kern import Matern32\\n  File \"tmp/venv/GPy/__init__.py\", line 15, in <module>\\n    from . import plotting\\n  File \"tmp/venv/GPy/plotting/__init__.py\", line 156, in <mo...'}, {'id': '[1685086333837, 9685803]', 'time': '2023-05-26T07:32:13.837Z', 'level': 'error', 'message': 'YARN application status reports error diagnostics: User application exited with status 1'}]\n",
      "Full logs can be inspected in an openEO (web) editor or with `connection.job('j-8b2ada7a1e9242aea6bbf91f7e1fc15e').logs()`.\n"
     ]
    },
    {
     "ename": "JobFailedException",
     "evalue": "Batch job 'j-8b2ada7a1e9242aea6bbf91f7e1fc15e' didn't finish successfully. Status: error (after 0:05:22).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJobFailedException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mogpr_job \u001b[38;5;241m=\u001b[39m \u001b[43mmogpr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjson\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFuseTS - MOGPR\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mudf-dependency-archives\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://artifactory.vgt.vito.be:443/auxdata-public/ai4food/fusets_venv.zip#tmp/venv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://artifactory.vgt.vito.be:443/auxdata-public/ai4food/fusets.zip#tmp/venv_static\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexecutor-memory\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m7g\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m mogpr_job\u001b[38;5;241m.\u001b[39mget_results()\u001b[38;5;241m.\u001b[39mdownload_file(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./mogpr.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/VITO/FuseTS/venv_py10/lib/python3.10/site-packages/openeo/rest/vectorcube.py:129\u001b[0m, in \u001b[0;36mVectorCube.execute_batch\u001b[0;34m(self, outputfile, out_format, print, max_poll_interval, connection_retry_interval, job_options, **format_options)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03mEvaluate the process graph by creating a batch job, and retrieving the results when it is finished.\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;124;03mThis method is mostly recommended if the batch job is expected to run in a reasonable amount of time.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    126\u001b[0m \n\u001b[1;32m    127\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    128\u001b[0m job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_job(out_format, job_options\u001b[38;5;241m=\u001b[39mjob_options, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_options)\n\u001b[0;32m--> 129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_synchronous\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# TODO #135 support multi file result sets too\u001b[39;49;00m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutputfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_poll_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_poll_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_retry_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnection_retry_interval\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/VITO/FuseTS/venv_py10/lib/python3.10/site-packages/openeo/rest/job.py:202\u001b[0m, in \u001b[0;36mBatchJob.run_synchronous\u001b[0;34m(self, outputfile, print, max_poll_interval, connection_retry_interval)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_synchronous\u001b[39m(\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;28mself\u001b[39m, outputfile: Union[\u001b[38;5;28mstr\u001b[39m, Path, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;28mprint\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mprint\u001b[39m, max_poll_interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m, connection_retry_interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m\n\u001b[1;32m    200\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBatchJob\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    201\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Start the job, wait for it to finish and download result\"\"\"\u001b[39;00m\n\u001b[0;32m--> 202\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_and_wait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_poll_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_poll_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_retry_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnection_retry_interval\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;66;03m# TODO #135 support multi file result sets too?\u001b[39;00m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m outputfile \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/VITO/FuseTS/venv_py10/lib/python3.10/site-packages/openeo/rest/job.py:284\u001b[0m, in \u001b[0;36mBatchJob.start_and_wait\u001b[0;34m(self, print, max_poll_interval, connection_retry_interval, soft_error_max)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogs(level\u001b[38;5;241m=\u001b[39mlogging\u001b[38;5;241m.\u001b[39mERROR))\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull logs can be inspected in an openEO (web) editor or with `connection.job(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_id\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m).logs()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JobFailedException(\n\u001b[1;32m    285\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch job \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_id\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt finish successfully. Status: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstatus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00melapsed()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    286\u001b[0m         job\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    287\u001b[0m     )\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[0;31mJobFailedException\u001b[0m: Batch job 'j-8b2ada7a1e9242aea6bbf91f7e1fc15e' didn't finish successfully. Status: error (after 0:05:22)."
     ]
    }
   ],
   "source": [
    "mogpr_job = mogpr.execute_batch(out_format=\"json\", title=f'FuseTS - MOGPR', job_options={\n",
    "    'udf-dependency-archives': [\n",
    "         'https://artifactory.vgt.vito.be:443/auxdata-public/ai4food/fusets_venv.zip#tmp/venv',\n",
    "        'https://artifactory.vgt.vito.be:443/auxdata-public/ai4food/fusets.zip#tmp/venv_static'\n",
    "    ],\n",
    "    'executor-memory': '7g'\n",
    "})\n",
    "mogpr_job.get_results().download_file('./mogpr.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9daefe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
