{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c767edf8",
   "metadata": {},
   "source": [
    "# FuseTS - Whittaker example\n",
    "This document displays the Whittaker algorithm, a component of the FuseTS library. The Whittaker algorithm is a smoothing algorithm that is designed to handle time series data. The algorithm is effective in removing noise and other fluctuations from time series data, which can be important when trying to understand trends in the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9100c1f5",
   "metadata": {},
   "source": [
    "## Setting up the OpenEO process\n",
    "The first step includes setting up the OpenEO processing through the [OpenEO Python Client](https://open-eo.github.io/openeo-python-client/). Since the Whittaker algorithm is integrated as an [user defined process](https://open-eo.github.io/openeo-python-client/cookbook/udp_sharing.html), we can use the `datacube_from_process` function to execute the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "253e8623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openeo\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from openeo.rest.conversions import timeseries_json_to_pandas\n",
    "from shapely.geometry import box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1362bc74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To authenticate: visit https://aai.egi.eu/device?user_code=JFZH-GUPH .\n",
      "Authorized successfully.\n",
      "Authenticated using device code flow.\n"
     ]
    }
   ],
   "source": [
    "connection = openeo.connect(\"openeo.vito.be\").authenticate_oidc()\n",
    "service = 'whittaker'\n",
    "namespace = 'u:bramjanssen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0579f9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <script>\n",
       "    if (!window.customElements || !window.customElements.get('openeo-process')) {\n",
       "        var el = document.createElement('script');\n",
       "        el.src = \"https://cdn.jsdelivr.net/npm/@openeo/vue-components@2/assets/openeo.min.js\";\n",
       "        document.head.appendChild(el);\n",
       "\n",
       "        var font = document.createElement('font');\n",
       "        font.as = \"font\";\n",
       "        font.type = \"font/woff2\";\n",
       "        font.crossOrigin = true;\n",
       "        font.href = \"https://use.fontawesome.com/releases/v5.13.0/webfonts/fa-solid-900.woff2\"\n",
       "        document.head.appendChild(font);\n",
       "    }\n",
       "    </script>\n",
       "    <openeo-process>\n",
       "        <script type=\"application/json\">{\"show-graph\": true, \"provide-download\": false, \"process\": {\"description\": \"# Whittaker\\n\\n## Description\\n\\nWhittaker represents a computationally efficient reconstruction method for smoothing and gap-filling of time series.\\nThe main function takes as input two vectors of the same length: the y time series data (e.g. NDVI) and the\\ncorresponding temporal vector (date format) x, comprised between the start and end dates of a satellite image\\ncollection. Missing or null values as well as the cloud-masked values (i.e. NaN), are handled by introducing a\\nvector of 0-1 weights w, with wi = 0 for missing observations and wi=1 otherwise. Following, the Whittaker smoother\\nis applied to the time series profiles, computing therefore a daily smoothing interpolation.\\n\\nWhittaker's fast processing speed was assessed through an initial performance testing by comparing different\\ntime series fitting methods. Average runtime takes 0.0107 seconds to process a single NDVI temporal profile.\\n\\nThe smoother performance can be adjusted by tuning the lambda parameter, which penalizes the time series roughness:\\nthe larger lambda the smoother the time series at the cost of the fit to the data getting worse. We found a lambda of\\n10000 adequate for obtaining more convenient results. A more detailed description of the algorithm can be\\nfound in the original work of Eilers 2003.\\n\\n\\n\\n\", \"id\": \"whittaker\", \"parameters\": [{\"description\": \"A data cube.\", \"name\": \"data\", \"schema\": {\"subtype\": \"raster-cube\", \"type\": \"object\"}}, {\"description\": \"Lambda parameter to change the Whittaker smoothing\", \"name\": \"smoothing_lambda\", \"schema\": {\"type\": \"number\"}}], \"summary\": \"Execute a computationally efficient reconstruction method for smoothing and gap-filling of time series.\"}}</script>\n",
       "    </openeo-process>\n",
       "    "
      ],
      "text/plain": [
       "{'description': \"# Whittaker\\n\\n## Description\\n\\nWhittaker represents a computationally efficient reconstruction method for smoothing and gap-filling of time series.\\nThe main function takes as input two vectors of the same length: the y time series data (e.g. NDVI) and the\\ncorresponding temporal vector (date format) x, comprised between the start and end dates of a satellite image\\ncollection. Missing or null values as well as the cloud-masked values (i.e. NaN), are handled by introducing a\\nvector of 0-1 weights w, with wi = 0 for missing observations and wi=1 otherwise. Following, the Whittaker smoother\\nis applied to the time series profiles, computing therefore a daily smoothing interpolation.\\n\\nWhittaker's fast processing speed was assessed through an initial performance testing by comparing different\\ntime series fitting methods. Average runtime takes 0.0107 seconds to process a single NDVI temporal profile.\\n\\nThe smoother performance can be adjusted by tuning the lambda parameter, which penalizes the time series roughness:\\nthe larger lambda the smoother the time series at the cost of the fit to the data getting worse. We found a lambda of\\n10000 adequate for obtaining more convenient results. A more detailed description of the algorithm can be\\nfound in the original work of Eilers 2003.\\n\\n\\n\\n\",\n",
       " 'id': 'whittaker',\n",
       " 'parameters': [{'description': 'A data cube.',\n",
       "   'name': 'data',\n",
       "   'schema': {'subtype': 'raster-cube', 'type': 'object'}},\n",
       "  {'description': 'Lambda parameter to change the Whittaker smoothing',\n",
       "   'name': 'smoothing_lambda',\n",
       "   'schema': {'type': 'number'}}],\n",
       " 'summary': 'Execute a computationally efficient reconstruction method for smoothing and gap-filling of time series.'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connection.describe_process(service, namespace=namespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b9efbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spat_ext = {\n",
    "          \"type\": \"Polygon\",\n",
    "          \"coordinates\": [\n",
    "            [\n",
    "              [\n",
    "                5.170012098271149,\n",
    "                51.25062964728295\n",
    "              ],\n",
    "              [\n",
    "                5.17085904378298,\n",
    "                51.24882567194015\n",
    "              ],\n",
    "              [\n",
    "                5.17857421368097,\n",
    "                51.2468515482926\n",
    "              ],\n",
    "              [\n",
    "                5.178972704726344,\n",
    "                51.24982704376254\n",
    "              ],\n",
    "              [\n",
    "                5.170012098271149,\n",
    "                51.25062964728295\n",
    "              ]\n",
    "            ]\n",
    "          ]\n",
    "        }\n",
    "temp_ext = [\"2023-01-01\",\"2023-03-31\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bad2439",
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothing_lambda = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e3d0662",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = connection.load_collection('SENTINEL2_L2A_SENTINELHUB',\n",
    "                                spatial_extent=spat_ext,\n",
    "                                temporal_extent=temp_ext,\n",
    "                                bands=[\"B04\",\"B08\",\"SCL\"])\n",
    "base_cloudmasked = base.process(\"mask_scl_dilation\", data=base, scl_band_name=\"SCL\")\n",
    "base_ndvi = base_cloudmasked.ndvi(red=\"B04\", nir=\"B08\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec52ef73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bramjanssen/.local/lib/python3.6/site-packages/openeo/metadata.py:255: UserWarning: No cube:dimensions metadata\n",
      "  complain(\"No cube:dimensions metadata\")\n"
     ]
    }
   ],
   "source": [
    "whittaker = connection.datacube_from_process(service, namespace=f'https://openeo.vito.be/openeo/1.1/processes/{namespace}/{service}', data=base_ndvi, smoothing_lambda=smoothing_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b3a4866",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserDeprecationWarning: Call to deprecated method polygonal_mean_timeseries. (Use `aggregate_spatial` with reducer ``'mean'``.) -- Deprecated since version 0.10.0.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserDeprecationWarning: Call to deprecated method polygonal_mean_timeseries. (Use `aggregate_spatial` with reducer ``'mean'``.) -- Deprecated since version 0.10.0.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "base_ndvi = base_ndvi.polygonal_mean_timeseries(spat_ext)\n",
    "whittaker = whittaker.polygonal_mean_timeseries(spat_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28b30d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00 Job 'j-f3fe6b8e24c4480d99bdf87051e3b265': send 'start'\n",
      "0:00:30 Job 'j-f3fe6b8e24c4480d99bdf87051e3b265': queued (progress N/A)\n",
      "0:00:35 Job 'j-f3fe6b8e24c4480d99bdf87051e3b265': queued (progress N/A)\n",
      "0:00:42 Job 'j-f3fe6b8e24c4480d99bdf87051e3b265': queued (progress N/A)\n",
      "0:00:50 Job 'j-f3fe6b8e24c4480d99bdf87051e3b265': queued (progress N/A)\n",
      "0:01:00 Job 'j-f3fe6b8e24c4480d99bdf87051e3b265': queued (progress N/A)\n",
      "0:01:13 Job 'j-f3fe6b8e24c4480d99bdf87051e3b265': queued (progress N/A)\n",
      "0:01:28 Job 'j-f3fe6b8e24c4480d99bdf87051e3b265': queued (progress N/A)\n",
      "0:01:47 Job 'j-f3fe6b8e24c4480d99bdf87051e3b265': queued (progress N/A)\n",
      "0:02:11 Job 'j-f3fe6b8e24c4480d99bdf87051e3b265': running (progress N/A)\n",
      "0:02:41 Job 'j-f3fe6b8e24c4480d99bdf87051e3b265': running (progress N/A)\n",
      "0:03:19 Job 'j-f3fe6b8e24c4480d99bdf87051e3b265': running (progress N/A)\n",
      "0:04:06 Job 'j-f3fe6b8e24c4480d99bdf87051e3b265': error (progress N/A)\n",
      "Your batch job 'j-f3fe6b8e24c4480d99bdf87051e3b265' failed. Error logs:\n",
      "[{'id': '[1682404732339, 618]', 'time': '2023-04-25T06:38:52.339Z', 'level': 'error', 'message': 'Exception in task 0.0 in stage 15.0 (TID 131)'}, {'id': '[1682404734292, 618]', 'time': '2023-04-25T06:38:54.292Z', 'level': 'error', 'message': 'Exception in task 0.1 in stage 15.0 (TID 132)'}, {'id': '[1682404746927, 0]', 'time': '2023-04-25T06:39:06.927Z', 'level': 'error', 'message': 'Exception in task 0.2 in stage 15.0 (TID 133)'}, {'id': '[1682404752938, 0]', 'time': '2023-04-25T06:39:12.938Z', 'level': 'error', 'message': 'Exception in task 0.3 in stage 15.0 (TID 134)'}, {'id': '[1682404752981, 43466]', 'time': '2023-04-25T06:39:12.981Z', 'level': 'error', 'message': 'Aborting job a06eb640-fde4-4916-bcb9-d87deed14531.'}, {'id': '[1682404753812, 29771]', 'time': '2023-04-25T06:39:13.812Z', 'level': 'error', 'message': 'OpenEO batch job failed: UDF Exception during Spark execution:   File \"<string>\", line 29, in apply_datacube\\n  File \"tmp/venv_static/fusets/whittaker.py\", line 114, in whittaker\\n    result = xarray.apply_ufunc(callback, array, input_core_dims=[[time_dimension]], output_core_dims=[[output_time_dimension]],vectorize=True)\\n  File \"/opt/venv/lib64/python3.8/site-packages/xarray/core/computation.py\", line 1128, in apply_ufunc\\n    return apply_dataarray_vfunc(\\n  File \"/opt/venv/lib64/python3.8/site-packages/xarray/core/computation.py\", line 271, in apply_dataarray_vfunc\\n    result_var = func(*data_vars)\\n  File \"/opt/venv/lib64/python3.8/site-packages/xarray/core/computation.py\", line 724, in apply_variable_ufunc\\n    result_data = func(*input_data)\\n  File \"/opt/venv/lib64/python3.8/site-packages/numpy/lib/function_base.py\", line 2304, in __call__\\n    return self._vectorize_call(func=func, args=vargs)\\n  File \"/opt/venv/lib64/python3.8/site-packages/numpy/lib/function_base.py\", line 2378, in _vectorize_call\\n    res = self._vectorize_call_with_signature(func, args)\\n  File \"/opt/venv/lib64/python3.8/site-packages/numpy/lib/function_base.py\", line 2418, in _vectorize_call_with_signature\\n    results = func(*(arg[index] for arg in args))\\n  File \"tmp/venv_static/fusets/whittaker.py\", line 107, in callback\\n    z1_, xx, Zd, XXd = whittaker_f(dates, timeseries, smoothing_lambda, 1)\\n  File \"tmp/venv_static/fusets/whittaker.py\", line 173, in whittaker_f\\n    z_ = ws2d(t, lmbd, w)\\n  File \"src/_whittaker.pyx\", line 67, in vam.whittaker.ws2d\\nTypeError: must be real number, not NoneType'}]\n",
      "Full logs can be inspected in an openEO (web) editor or with `connection.job('j-f3fe6b8e24c4480d99bdf87051e3b265').logs()`.\n"
     ]
    },
    {
     "ename": "JobFailedException",
     "evalue": "Batch job 'j-f3fe6b8e24c4480d99bdf87051e3b265' didn't finish successfully. Status: error (after 0:04:06).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJobFailedException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3fb9640d55da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     'udf-dependency-archives': [\n\u001b[1;32m      3\u001b[0m          \u001b[0;34m'https://artifactory.vgt.vito.be:443/auxdata-public/ai4food/fusets_venv.zip#tmp/venv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;34m'https://artifactory.vgt.vito.be:443/auxdata-public/ai4food/fusets.zip#tmp/venv_static'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     ]\n\u001b[1;32m      6\u001b[0m })\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/openeo/rest/datacube.py\u001b[0m in \u001b[0;36mexecute_batch\u001b[0;34m(self, outputfile, out_format, print, max_poll_interval, connection_retry_interval, job_options, **format_options)\u001b[0m\n\u001b[1;32m   1909\u001b[0m         return job.run_synchronous(\n\u001b[1;32m   1910\u001b[0m             \u001b[0moutputfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_poll_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_poll_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection_retry_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconnection_retry_interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m         )\n\u001b[1;32m   1913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/openeo/rest/job.py\u001b[0m in \u001b[0;36mrun_synchronous\u001b[0;34m(self, outputfile, print, max_poll_interval, connection_retry_interval)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;34m\"\"\"Start the job, wait for it to finish and download result\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         self.start_and_wait(\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_poll_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_poll_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection_retry_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconnection_retry_interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         )\n\u001b[1;32m    189\u001b[0m         \u001b[0;31m# TODO #135 support multi file result sets too?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/openeo/rest/job.py\u001b[0m in \u001b[0;36mstart_and_wait\u001b[0;34m(self, print, max_poll_interval, connection_retry_interval, soft_error_max)\u001b[0m\n\u001b[1;32m    268\u001b[0m             raise JobFailedException(\n\u001b[1;32m    269\u001b[0m                 \u001b[0;34mf\"Batch job {self.job_id!r} didn't finish successfully. Status: {status} (after {elapsed()}).\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m                 \u001b[0mjob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m             )\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJobFailedException\u001b[0m: Batch job 'j-f3fe6b8e24c4480d99bdf87051e3b265' didn't finish successfully. Status: error (after 0:04:06)."
     ]
    }
   ],
   "source": [
    "whittaker_job = whittaker.execute_batch(out_format=\"json\", title=f'AI4FOOD - Whittaker', job_options={\n",
    "    'udf-dependency-archives': [\n",
    "         'https://artifactory.vgt.vito.be:443/auxdata-public/ai4food/fusets_venv.zip#tmp/venv',\n",
    "        'https://artifactory.vgt.vito.be:443/auxdata-public/ai4food/fusets.zip#tmp/venv_static'\n",
    "    ]\n",
    "})\n",
    "whittaker_job.get_results().download_file('./whittaker.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5cbc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_ndvi.download('./base.json', format='json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972c755d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d156be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cubes_dfs = []\n",
    "cols = ['Raw NDVI', 'Whittaker NDVI']\n",
    "for result in ['base.json', 'result.json']:\n",
    "    with open(result, 'r') as result_file:\n",
    "        df = timeseries_json_to_pandas(json.load(result_file))\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        cubes_dfs.append(df)    \n",
    "        result_file.close()\n",
    "joined_df = pd.concat(cubes_dfs, axis=1)\n",
    "joined_df = joined_df.rename(columns={0: cols[0], 1: cols[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d37329",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (16,6))\n",
    "for col in cols:\n",
    "    plt.plot(joined_df.index, joined_df[col], 'o', label=col)\n",
    "plt.ylabel ('NDVI')\n",
    "plt.grid(True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445011b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
